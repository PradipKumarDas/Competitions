{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Author**: _Pradip Kumar Das_\n",
    "\n",
    "**License:** https://github.com/PradipKumarDas/Competitions/blob/main/LICENSE\n",
    "\n",
    "**Profile & Contact:** [LinkedIn](https://www.linkedin.com/in/daspradipkumar/) | [GitHub](https://github.com/PradipKumarDas) | [Kaggle](https://www.kaggle.com/pradipkumardas) | pradipkumardas@hotmail.com (Email)\n",
    "\n",
    "# Tabular Playground Series - Feb. 2022\n",
    "\n",
    "**Feb 01, 2022 to Feb 28, 2022**\n",
    "\n",
    "https://www.kaggle.com/c/tabular-playground-series-feb-2022/\n",
    "\n",
    "_**Predicting bacteria species.**_\n",
    "\n",
    "**Sections:**\n",
    "- Dependencies\n",
    "- Exploratory Data Analysis (EDA) & Preprocessing\n",
    "- Modeling & Evaluation\n",
    "- Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loads required packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis (EDA) & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loads train dataset\n",
    "train = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>A0T0G0C10</th>\n",
       "      <th>A0T0G1C9</th>\n",
       "      <th>A0T0G2C8</th>\n",
       "      <th>A0T0G3C7</th>\n",
       "      <th>A0T0G4C6</th>\n",
       "      <th>A0T0G5C5</th>\n",
       "      <th>A0T0G6C4</th>\n",
       "      <th>A0T0G7C3</th>\n",
       "      <th>A0T0G8C2</th>\n",
       "      <th>...</th>\n",
       "      <th>A8T0G1C1</th>\n",
       "      <th>A8T0G2C0</th>\n",
       "      <th>A8T1G0C1</th>\n",
       "      <th>A8T1G1C0</th>\n",
       "      <th>A8T2G0C0</th>\n",
       "      <th>A9T0G0C1</th>\n",
       "      <th>A9T0G1C0</th>\n",
       "      <th>A9T1G0C0</th>\n",
       "      <th>A10T0G0C0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>Streptococcus_pyogenes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>Salmonella_enterica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.046326e-06</td>\n",
       "      <td>Salmonella_enterica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.632568e-08</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>Salmonella_enterica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>Enterococcus_hirae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 288 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     A0T0G0C10  A0T0G1C9  A0T0G2C8  A0T0G3C7  A0T0G4C6  A0T0G5C5  \\\n",
       "0       0 -9.536743e-07 -0.000010 -0.000043 -0.000114 -0.000200 -0.000240   \n",
       "1       1 -9.536743e-07 -0.000010 -0.000043  0.000886 -0.000200  0.000760   \n",
       "2       2 -9.536743e-07 -0.000002  0.000007  0.000129  0.000268  0.000270   \n",
       "3       3  4.632568e-08 -0.000006  0.000012  0.000245  0.000492  0.000522   \n",
       "4       4 -9.536743e-07 -0.000010 -0.000043 -0.000114 -0.000200 -0.000240   \n",
       "\n",
       "   A0T0G6C4  A0T0G7C3  A0T0G8C2  ...  A8T0G1C1  A8T0G2C0  A8T1G0C1  A8T1G1C0  \\\n",
       "0 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043 -0.000086 -0.000086   \n",
       "1 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043  0.000914  0.000914   \n",
       "2  0.000243  0.000125  0.000001  ...  0.000084  0.000048  0.000081  0.000106   \n",
       "3  0.000396  0.000197 -0.000003  ...  0.000151  0.000100  0.000180  0.000202   \n",
       "4 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043 -0.000086 -0.000086   \n",
       "\n",
       "   A8T2G0C0  A9T0G0C1  A9T0G1C0  A9T1G0C0     A10T0G0C0  \\\n",
       "0 -0.000043 -0.000010 -0.000010 -0.000010 -9.536743e-07   \n",
       "1 -0.000043 -0.000010 -0.000010 -0.000010 -9.536743e-07   \n",
       "2  0.000072  0.000010  0.000008  0.000019  1.046326e-06   \n",
       "3  0.000153  0.000021  0.000015  0.000046 -9.536743e-07   \n",
       "4 -0.000043 -0.000010 -0.000010 -0.000010 -9.536743e-07   \n",
       "\n",
       "                   target  \n",
       "0  Streptococcus_pyogenes  \n",
       "1     Salmonella_enterica  \n",
       "2     Salmonella_enterica  \n",
       "3     Salmonella_enterica  \n",
       "4      Enterococcus_hirae  \n",
       "\n",
       "[5 rows x 288 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checks how the train data set looks\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindexes train data set with 'row_id'\n",
    "train.set_index([\"row_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200000 entries, 0 to 199999\n",
      "Columns: 287 entries, A0T0G0C10 to target\n",
      "dtypes: float64(286), object(1)\n",
      "memory usage: 439.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Shows the summary of the train data set\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in train data: 76007\n"
     ]
    }
   ],
   "source": [
    "# Checks for duplicates\n",
    "print(f\"Duplicates in train data: {train.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "train.drop_duplicates(keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks for any missing values\n",
    "train.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As all classifier algorithms are not scale variant, let's see if any of the\n",
    "# columns having\n",
    "\n",
    "train_min_max = train.describe().transpose()[[\"min\", \"max\"]]\n",
    "\n",
    "train_min_max.columns = [\"minimum\", \"maximum\"]\n",
    "\n",
    "train_min_max.query('`minimum` < -1.0 or `maximum` > 1.0').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value 0 confirms that values of all columns ranges from -1 to +1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)  \n",
    "        # else:\n",
    "        #     df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: \n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 68.58 Mb (74.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Compresses the train data set\n",
    "train = reduce_mem_usage(train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123993 entries, 0 to 123992\n",
      "Columns: 287 entries, A0T0G0C10 to target\n",
      "dtypes: float16(286), object(1)\n",
      "memory usage: 68.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Shows the summary of the train data set post compression\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads test data\n",
    "test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets \"row_id\" as index\n",
    "test.set_index([\"row_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 200000 to 299999\n",
      "Columns: 286 entries, A0T0G0C10 to A10T0G0C0\n",
      "dtypes: float64(286)\n",
      "memory usage: 219.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Shows the summary of the test data set\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 55.31 Mb (74.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Compresses the test data set\n",
    "test = reduce_mem_usage(test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 200000 to 299999\n",
      "Columns: 286 entries, A0T0G0C10 to A10T0G0C0\n",
      "dtypes: float16(286)\n",
      "memory usage: 55.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Shows the summary of the test data set post compression\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows between test and test dataset: 486\n"
     ]
    }
   ],
   "source": [
    "# Checks for duplicate in data set by finding any rows common to both train and test data set\n",
    "print(\n",
    "    \"Number of duplicate rows between test and test dataset:\", \n",
    "    len(test.merge(train, on=list(train.select_dtypes([\"float16\"]).columns), how=\"inner\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of Samples</th>\n",
       "      <th>Class Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bacteroides_fragilis</th>\n",
       "      <td>12522</td>\n",
       "      <td>10.098957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Campylobacter_jejuni</th>\n",
       "      <td>12469</td>\n",
       "      <td>10.056213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klebsiella_pneumoniae</th>\n",
       "      <td>12420</td>\n",
       "      <td>10.016694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Streptococcus_pneumoniae</th>\n",
       "      <td>12416</td>\n",
       "      <td>10.013469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Staphylococcus_aureus</th>\n",
       "      <td>12415</td>\n",
       "      <td>10.012662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Streptococcus_pyogenes</th>\n",
       "      <td>12406</td>\n",
       "      <td>10.005404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salmonella_enterica</th>\n",
       "      <td>12390</td>\n",
       "      <td>9.992500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enterococcus_hirae</th>\n",
       "      <td>12373</td>\n",
       "      <td>9.978789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Escherichia_coli</th>\n",
       "      <td>12297</td>\n",
       "      <td>9.917495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Escherichia_fergusonii</th>\n",
       "      <td>12285</td>\n",
       "      <td>9.907817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          No. of Samples  Class Percentile\n",
       "Bacteroides_fragilis               12522         10.098957\n",
       "Campylobacter_jejuni               12469         10.056213\n",
       "Klebsiella_pneumoniae              12420         10.016694\n",
       "Streptococcus_pneumoniae           12416         10.013469\n",
       "Staphylococcus_aureus              12415         10.012662\n",
       "Streptococcus_pyogenes             12406         10.005404\n",
       "Salmonella_enterica                12390          9.992500\n",
       "Enterococcus_hirae                 12373          9.978789\n",
       "Escherichia_coli                   12297          9.917495\n",
       "Escherichia_fergusonii             12285          9.907817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shows label distribution as number of samples in each class and percentile of each class\n",
    "display(pd.DataFrame(\n",
    "    {\"No. of Samples\": train.target.value_counts(), \n",
    "     \"Class Percentile\": train.target.value_counts()/len(train)*100}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above distribution for label indicates that the dataset is mostly balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a DataFrame for features intersection between train and test data set\n",
    "\n",
    "intersection = test.copy()\n",
    "intersection[\"row_index\"] = intersection.index\n",
    "intersection = intersection.merge(train, on=list(train.select_dtypes([\"float16\"]).columns), how=\"inner\")\n",
    "intersection.set_index([\"row_index\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodes the labels\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train.target = label_encoder.fit_transform(train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperates label from features\n",
    "\n",
    "X = train.select_dtypes([\"float16\"])\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodes the labels in intersection data set, too\n",
    "intersection.target = label_encoder.transform(intersection.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps only label agaisnt index\n",
    "intersection = intersection.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a stratified splitter\n",
    "k_folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, Accuracy: 0.8981451612903226\n",
      "FOLD: 1, Accuracy: 0.9019354838709678\n",
      "FOLD: 2, Accuracy: 0.9025\n",
      "FOLD: 3, Accuracy: 0.8948302282442132\n",
      "FOLD: 4, Accuracy: 0.8975723848697476\n",
      "FOLD: 5, Accuracy: 0.8989434631825147\n",
      "FOLD: 6, Accuracy: 0.8991047665134285\n",
      "FOLD: 7, Accuracy: 0.9033793047826437\n",
      "FOLD: 8, Accuracy: 0.8977336882006614\n",
      "FOLD: 9, Accuracy: 0.9066053714009195\n",
      "Mean Accuracy: 0.9000749852355419\n"
     ]
    }
   ],
   "source": [
    "# Performs modeling with Decision Tree with defaul parameters\n",
    "\n",
    "cv_accuracy.clear()\n",
    "for i, (train_idx, test_idx) in enumerate(k_folds.split(X, y)):\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X=X.loc[train_idx], y=y.loc[train_idx])\n",
    "    predictions = clf.predict(X=X.loc[test_idx])\n",
    "    accuracy = accuracy_score(y.loc[test_idx], predictions)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    print(f\"FOLD: {i}, Accuracy: {accuracy}\")\n",
    "print(f\"Mean Accuracy: {np.mean(cv_accuracy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, Accuracy: 0.9706451612903226\n",
      "FOLD: 1, Accuracy: 0.967741935483871\n",
      "FOLD: 2, Accuracy: 0.9672580645161291\n",
      "FOLD: 3, Accuracy: 0.9674973788208726\n",
      "FOLD: 4, Accuracy: 0.9696749737882088\n",
      "FOLD: 5, Accuracy: 0.9708847487700621\n",
      "FOLD: 6, Accuracy: 0.9706427937736914\n",
      "FOLD: 7, Accuracy: 0.9720945237519155\n",
      "FOLD: 8, Accuracy: 0.9699975804500363\n",
      "FOLD: 9, Accuracy: 0.9712073554318896\n",
      "Mean Accuracy: 0.9697644516076999\n"
     ]
    }
   ],
   "source": [
    "# Performs modeling with Random Forests with defaul parameters\n",
    "\n",
    "cv_accuracy.clear()\n",
    "for i, (train_idx, test_idx) in enumerate(k_folds.split(X, y)):\n",
    "    clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "    clf.fit(X=X.loc[train_idx], y=y.loc[train_idx])\n",
    "    predictions = clf.predict(X=X.loc[test_idx])\n",
    "    accuracy = accuracy_score(y.loc[test_idx], predictions)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    print(f\"FOLD: {i}, Accuracy: {accuracy}\")\n",
    "print(f\"Mean Accuracy: {np.mean(cv_accuracy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, Accuracy: 0.9716129032258064\n",
      "FOLD: 1, Accuracy: 0.9689516129032258\n",
      "FOLD: 2, Accuracy: 0.9682258064516129\n",
      "FOLD: 3, Accuracy: 0.970239535446407\n",
      "FOLD: 4, Accuracy: 0.9700782321154932\n",
      "FOLD: 5, Accuracy: 0.9742721187192516\n",
      "FOLD: 6, Accuracy: 0.9712880070973465\n",
      "FOLD: 7, Accuracy: 0.9725784337446568\n",
      "FOLD: 8, Accuracy: 0.969513670457295\n",
      "FOLD: 9, Accuracy: 0.9718525687555448\n"
     ]
    }
   ],
   "source": [
    "# Performs modeling with Random Forests with defaul parameters\n",
    "\n",
    "cv_accuracy.clear()\n",
    "for i, (train_idx, test_idx) in enumerate(k_folds.split(X, y)):\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "    clf.fit(X=X.loc[train_idx], y=y.loc[train_idx])\n",
    "    predictions = clf.predict(X=X.loc[test_idx])\n",
    "    accuracy = accuracy_score(y.loc[test_idx], predictions)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    print(f\"FOLD: {i}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9708612888916639\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Accuracy: {np.mean(cv_accuracy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, Accuracy: 0.967983870967742\n",
      "FOLD: 1, Accuracy: 0.967741935483871\n",
      "FOLD: 2, Accuracy: 0.9687096774193549\n",
      "FOLD: 3, Accuracy: 0.967255423824502\n",
      "FOLD: 4, Accuracy: 0.9682232438099847\n",
      "FOLD: 5, Accuracy: 0.9710460521009758\n",
      "FOLD: 6, Accuracy: 0.9708847487700621\n",
      "FOLD: 7, Accuracy: 0.9699975804500363\n",
      "FOLD: 8, Accuracy: 0.967981288813614\n",
      "FOLD: 9, Accuracy: 0.9717719170900879\n",
      "Mean Accuracy: 0.9691595738730232\n"
     ]
    }
   ],
   "source": [
    "# Performs modeling with LightGBM with defaul parameters\n",
    "\n",
    "cv_accuracy.clear()\n",
    "for i, (train_idx, test_idx) in enumerate(k_folds.split(X, y)):\n",
    "    clf = lgb.LGBMClassifier(n_estimators=100, objective=\"multiclass\", n_jobs=-1, random_state=42)\n",
    "    clf.fit(X.loc[train_idx], y=y.loc[train_idx], eval_metric=\"multi_logloss\")\n",
    "    predictions = clf.predict(X=X.loc[test_idx])\n",
    "    accuracy = accuracy_score(y.loc[test_idx], predictions)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    print(f\"FOLD: {i}, Accuracy: {accuracy}\")\n",
    "print(f\"Mean Accuracy: {np.mean(cv_accuracy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply stacked generalization with models Random Forests, Extra Trees and LightGBM as these all performed well on cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0\n",
      "\tRandom Forests: Training...done. OOF accuracy...0.9749193548387097. Predicting on test...done.\n",
      "\n",
      "\tExtra Trees: Training...done. OOF accuracy...0.9759677419354839. Predicting on test...done.\n",
      "\n",
      "\tLightGBM: Training...done. OOF accuracy...0.9766935483870968. Predicting on test...done.\n",
      "\n",
      "FOLD: 1\n",
      "\tRandom Forests: Training...done. OOF accuracy...0.9718548387096774. Predicting on test...done.\n",
      "\n",
      "\tExtra Trees: Training...done. OOF accuracy...0.9735483870967742. Predicting on test...done.\n",
      "\n",
      "\tLightGBM: Training...done. OOF accuracy...0.9733870967741935. Predicting on test...done.\n",
      "\n",
      "FOLD: 2\n",
      "\tRandom Forests: Training...done. OOF accuracy...0.9721774193548387. Predicting on test...done.\n",
      "\n",
      "\tExtra Trees: Training...done. OOF accuracy...0.974516129032258. Predicting on test...done.\n",
      "\n",
      "\tLightGBM: Training...done. OOF accuracy...0.9743548387096774. Predicting on test...done.\n",
      "\n",
      "FOLD: 3\n",
      "\tRandom Forests: Training...done. OOF accuracy...0.9734656020646827. Predicting on test...done.\n",
      "\n",
      "\tExtra Trees: Training...done. OOF accuracy...0.9737882087265102. Predicting on test...done.\n",
      "\n",
      "\tLightGBM: Training...done. OOF accuracy...0.9772562303411565. Predicting on test...done.\n",
      "\n",
      "FOLD: 4\n",
      "\tRandom Forests: Training...done. OOF accuracy...0.9738688603919671. Predicting on test...done.\n",
      "\n",
      "\tExtra Trees: Training...done. OOF accuracy...0.9757238486974756. Predicting on test...done.\n",
      "\n",
      "\tLightGBM: Training...done. OOF accuracy...0.9755625453665618. Predicting on test...done.\n",
      "\n",
      "FOLD: 5\n",
      "\tRandom Forests: Training...done. OOF accuracy...0.9749979837083635. Predicting on test...done.\n",
      "\n",
      "\tExtra Trees: Training...done. OOF accuracy...0.9777401403338979. Predicting on test...done.\n",
      "\n",
      "\tLightGBM: Training...done. OOF accuracy...0.9779820953302686. Predicting on test...done.\n",
      "\n",
      "FOLD: 6\n",
      "\tRandom Forests: Training...done. OOF accuracy...0.9743527703847085. Predicting on test...done.\n",
      "\n",
      "\tExtra Trees: Training...done. OOF accuracy...0.9749173320429066. Predicting on test...done.\n",
      "\n",
      "\tLightGBM: Training...done. OOF accuracy...0.9774175336720703. Predicting on test...done.\n",
      "\n",
      "FOLD: 7\n",
      "\tRandom Forests: Training...done. OOF accuracy...0.9748366803774497. Predicting on test...done.\n",
      "\n",
      "\tExtra Trees: Training...done. OOF accuracy...0.9770949270102428. Predicting on test...done.\n",
      "\n",
      "\tLightGBM: Training...done. OOF accuracy...0.9777401403338979. Predicting on test...done.\n",
      "\n",
      "FOLD: 8\n",
      "\tRandom Forests: Training...done. OOF accuracy...0.9734656020646827. Predicting on test...done.\n",
      "\n",
      "\tExtra Trees: Training...done. OOF accuracy...0.9742721187192516. Predicting on test...done.\n",
      "\n",
      "\tLightGBM: Training...done. OOF accuracy...0.9759658036938462. Predicting on test...done.\n",
      "\n",
      "FOLD: 9\n",
      "\tRandom Forests: Training...done. OOF accuracy...0.9764497136865876. Predicting on test...done.\n",
      "\n",
      "\tExtra Trees: Training...done. OOF accuracy...0.9773368820066134. Predicting on test...done.\n",
      "\n",
      "\tLightGBM: Training...done. OOF accuracy...0.9784660053230099. Predicting on test...done.\n",
      "\n",
      "Average cross validation accuracy: 0.9753373459704954\n"
     ]
    }
   ],
   "source": [
    "# Traines the first level models and stores predictions (probabilities) of out of fold data set\n",
    "\n",
    "cv_predictions_proba = []\n",
    "cv_labels = []\n",
    "cv_avg_accuracy = []\n",
    "test_predictions_proba = []\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(k_folds.split(X, y)):\n",
    "    clfs = [\n",
    "        (\"Random Forests\", RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)), \n",
    "        (\"Extra Trees\", ExtraTreesClassifier(n_estimators=300, n_jobs=-1, random_state=42)), \n",
    "        (\"LightGBM\", lgb.LGBMClassifier(n_estimators=300, objective=\"multiclass\", n_jobs=-1, random_state=42))\n",
    "    ]\n",
    "    print(f\"FOLD: {i}\")\n",
    "    for clf in clfs:\n",
    "        print(f\"\\t{clf[0]}: Training...\", end=\"\")\n",
    "        clf[1].fit(X=X.loc[train_idx], y=y.loc[train_idx])\n",
    "        print(\"done. OOF accuracy...\", end=\"\")\n",
    "        predictions = clf[1].predict(X=X.loc[test_idx])\n",
    "        cv_predictions_proba.append(clf[1].predict_proba(X=X.loc[test_idx]))\n",
    "        cv_labels.append(y.loc[test_idx])\n",
    "        accuracy = accuracy_score(y.loc[test_idx], predictions)\n",
    "        cv_avg_accuracy.append(accuracy)\n",
    "        print(f\"{accuracy}.\", end=\" \")\n",
    "        print(f\"Predicting on test...\", end=\"\")\n",
    "        test_predictions_proba.append(clf[1].predict_proba(X=test))\n",
    "        print(\"done.\\n\")\n",
    "\n",
    "print(f\"Average cross validation accuracy: {np.mean(cv_avg_accuracy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenates all out of fold predicted label representations (probabilities) and\n",
    "# actual label into DataFrame and Series, respectively\n",
    "\n",
    "cv_predictions_proba = pd.DataFrame(np.concatenate(cv_predictions_proba))\n",
    "cv_labels = pd.Series(np.concatenate(cv_labels), name=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fits second level classifier\n",
    "\n",
    "second_level_clf = LogisticRegression(random_state=42, max_iter=200, n_jobs=-1)\n",
    "second_level_clf.fit(cv_predictions_proba, cv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store test predictions\n",
    "test_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second level classifier predicts over prediction probabilities\n",
    "# appends the predictions into list\n",
    "for predictions_proba in test_predictions_proba:\n",
    "    test_predictions.append(second_level_clf.predict(predictions_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposes for rows to indicate test samples and columns as predictions\n",
    "test_predictions = pd.DataFrame(test_predictions).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index of the prediction DataFrame to match that of test DataFrame\n",
    "test_predictions.set_index(np.arange(200000, 300000), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes those predictions that appear most often\n",
    "test_predictions = test_predictions.mode(axis=1, numeric_only=True)[0].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update predictions with ones from train data set intersecting with test data set\n",
    "test_predictions.loc[intersection.index] = intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves predictions into file for submission\n",
    "\n",
    "submission = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "submission.target = label_encoder.inverse_transform(test_predictions)\n",
    "submission.to_csv(\"./submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>Escherichia_fergusonii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>Salmonella_enterica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>Enterococcus_hirae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>Salmonella_enterica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>Staphylococcus_aureus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                  target\n",
       "0  200000  Escherichia_fergusonii\n",
       "1  200001     Salmonella_enterica\n",
       "2  200002      Enterococcus_hirae\n",
       "3  200003     Salmonella_enterica\n",
       "4  200004   Staphylococcus_aureus"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checks how the submission looks\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Leaderboard score against this submission was 0.97274 and highest score as on Feb 12, 2022 was 0.99006**_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
